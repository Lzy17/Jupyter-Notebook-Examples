{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Reading-CSV/TSV\">Reading CSV/TSV<a class=\"anchor-link\" href=\"#Reading-CSV/TSV\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The data we'll read comes from \n",
    "<a href=\"https://s3.amazonaws.com/amazon-reviews-pds/tsv/index.txt\">https://s3.amazonaws.com/amazon-reviews-pds/tsv/index.txt</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We'll read data from the \"Gift card\" category, which is fairly small. The raw data is here, and should be downloaded to your local machine:\n",
    "<a href=\"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Gift_Card_v1_00.tsv.gz\">https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Gift_Card_v1_00.tsv.gz</a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"/home/lizhaoyi/datasets/amazon/amazon_reviews_us_Gift_Card_v1_00.tsv.gz\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Note that the data is gzipped (filetype .gz). Rather than unzipping it, we can use the \"gzip\" library to read zipped data directly from the file</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gzip\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Using this library, we can open the data as if it were a regular file. \"rt\" converts from bytes to strings:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = gzip.open(path, 'rt', encoding=\"utf8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's look at one line of the file:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "header = f.readline()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "header\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>This line is called the \"header.\" Note that it contains the names of the fields we expect to find in the file. These fields are separeted by tabs (\\t) in a tsv file.</p>\n",
    "<p>We can extract these fields to a list using the \"split()\" function, which separates the string on the tab character:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "header = header.strip().split('\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "header\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We can now do the same thing to extract every line from the file, using a \"for\" loop:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lines = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for line in f:\n",
    "    fields = line.split('\\t')\n",
    "    lines.append(fields)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's look at the first line:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lines[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>It's hard to keep track of what each field means, but note that each entry corresponds to one field from the header. Using the \"zip\" function, we can match the header columns to the corresponding columns of the data:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z = zip(header, lines[0])\n",
    "list(z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Note that this data is now essentially what is known as a \"Key Value\" pair, where the first entry is the key, and the second is the value</p>\n",
    "<p>Python has a special data structure for dealing with key value pairs known as a \"dictionary\". This allows us to index the data using the keys directly. Let's convert this data to a dictionary:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = dict(zip(header, lines[0]))\n",
    "d\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Now we can directly query any of the fields:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d['customer_id']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d['star_rating']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>It might be useful to convert a few of the numerical fields from strings to integers:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d['star_rating'] = int(d['star_rating'])\n",
    "d['helpful_votes'] = int(d['helpful_votes'])\n",
    "d['total_votes'] = int(d['total_votes'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Finally, let's do the same thing for every line in the file, to build our dataset</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for line in lines:\n",
    "    # Convert to key-value pairs\n",
    "    d = dict(zip(header, line))\n",
    "    # Convert strings to integers for some fields:\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    d['helpful_votes'] = int(d['helpful_votes'])\n",
    "    d['total_votes'] = int(d['total_votes'])\n",
    "    dataset.append(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Now, we can easily perform queries on any entry in our dataset:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset[50]['star_rating']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Finally, while we've done these operations manually above, the same can be accomplished using the python csv library. Doing so saves us a few lines:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c = csv.reader(gzip.open(path, 'rt'), delimiter = '\\t')\n",
    "dataset = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first = True\n",
    "for line in c:\n",
    "    # The first line is the header\n",
    "    if first:\n",
    "        header = line\n",
    "        first = False\n",
    "    else:\n",
    "        d = dict(zip(header, line))\n",
    "        # Convert strings to integers for some fields:\n",
    "        d['star_rating'] = int(d['star_rating'])\n",
    "        d['helpful_votes'] = int(d['helpful_votes'])\n",
    "        d['total_votes'] = int(d['total_votes'])\n",
    "        dataset.append(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset[20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Avoiding-reading-large-files-into-disk\">Avoiding reading large files into disk<a class=\"anchor-link\" href=\"#Avoiding-reading-large-files-into-disk\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Note that it can be rather costly (in terms of memory) to read the entire file into a data structure, when we may only need to manipulate a small part of it at any one time. So, rather than reading the entire dataset into a data structure, this time we'll want to perform pre-processing on the dataset as we read each line.</p>\n",
    "<p>Let's suppose that for this exercise, we only care about extracting user, items, ratings, timestamps, and the \"verified_purchase\" flag:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = []\n",
    "header = f.readline().strip().split('\\t')\n",
    "for line in f:\n",
    "    line = line.split('\\t')\n",
    "    d = dict(zip(header, line))\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    d2 = {}\n",
    "    for field in ['star_rating', 'customer_id', 'product_id', 'review_date', 'verified_purchase']:\n",
    "        d2[field] = d[field]\n",
    "    dataset.append(d2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Computing-simple-statistics-from-data\">Computing simple statistics from data<a class=\"anchor-link\" href=\"#Computing-simple-statistics-from-data\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's quickly read the data again using the same code:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gzip\n",
    "path = \"/home/lizhaoyi/datasets/amazon/amazon_reviews_us_Gift_Card_v1_00.tsv.gz\"\n",
    "f = gzip.open(path, 'rt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = []\n",
    "# Read the header:\n",
    "header = f.readline().strip().split('\\t')\n",
    "for line in f:\n",
    "    # Separate by tabs\n",
    "    line = line.split('\\t')\n",
    "    # Convert to key-value pairs\n",
    "    d = dict(zip(header, line))\n",
    "    # Convert strings to integers for some fields:\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    d['helpful_votes'] = int(d['helpful_votes'])\n",
    "    d['total_votes'] = int(d['total_votes'])\n",
    "    dataset.append(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>By iterating through our dataset, we can straightforwardly compute some simple statistics, e.g. how many ratings are there?</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nRatings = len(dataset)\n",
    "nRatings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>And what is the average rating?</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "average = 0\n",
    "for d in dataset:\n",
    "    average += d['star_rating']\n",
    "average /= nRatings\n",
    "average\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>How many unique users and products are there in this dataset?</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "users = set()\n",
    "items = set()\n",
    "for d in dataset:\n",
    "    users.add(d['customer_id'])\n",
    "    items.add(d['product_id'])\n",
    "\n",
    "len(users),len(items)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"E.g.-What-is-the-average-rating-of-a-verified-purchase,-versus-an-unverified-purchase?\">E.g. What is the average rating of a verified purchase, versus an unverified purchase?<a class=\"anchor-link\" href=\"#E.g.-What-is-the-average-rating-of-a-verified-purchase,-versus-an-unverified-purchase?\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avVerified = 0\n",
    "avUnverified = 0\n",
    "nVerified = 0\n",
    "nUnverified = 0\n",
    "for d in dataset:\n",
    "    if d['verified_purchase'] == 'Y':\n",
    "        avVerified += d['star_rating']\n",
    "        nVerified += 1\n",
    "    else:\n",
    "        avUnverified += d['star_rating']\n",
    "        nUnverified += 1\n",
    "\n",
    "avVerified /= nVerified\n",
    "avUnverified /= nUnverified\n",
    "avVerified, avUnverified\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Many of these types of operations can be done more easily using operations known as \"list comprehensions\", which allow us to process and filter the data:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "verifiedRatings = [d['star_rating'] for d in dataset if d['verified_purchase'] == 'Y']\n",
    "unverifiedRatings = [d['star_rating'] for d in dataset if d['verified_purchase'] == 'N']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(sum(verifiedRatings) * 1.0 / len(verifiedRatings))\n",
    "print(sum(unverifiedRatings) * 1.0 / len(unverifiedRatings))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Reading-data-from-JSON\">Reading data from JSON<a class=\"anchor-link\" href=\"#Reading-data-from-JSON\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Another common data format is JSON (<a href=\"https://www.json.org/\">https://www.json.org/</a>). This format generalizes key-value pairs (like those that we saw in the previous notebooks), by allowing the values to <em>also</em> be key value pairs (allowing for hierarchical data).</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's look at an example of such data, this time from Yelp. This data is part of the \"Yelp dataset challenge\" and should first be downloaded locally before beginning this notebook:\n",
    "<a href=\"https://www.yelp.com/dataset/download\">https://www.yelp.com/dataset/download</a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"/home/lizhaoyi/datasets/yelp_data/review.json\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>This file is very large -- for the moment let's just look at the first 50,000 lines</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open(path, 'r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lines = []\n",
    "for i in range(50000):\n",
    "    lines.append(f.readline())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's just look at the first line:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lines[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Note that this looks very much like a python dictionary! In fact we could convert it directly to a python dictionary using the \"eval\" operator:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = eval(lines[0])\n",
    "d\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Then we could treat it just like a key-value pair:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d['user_id']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d['stars']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The \"eval\" operator isn't the safest though -- it's basically executing the line of the file as if it were native python code. This is a dangerous thing to do, especially if we don't trust the source of the file we're using.</p>\n",
    "<p>More safely, we can use the json library to read the data.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>and then read the data in the same way:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = json.loads(lines[0])\n",
    "d\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's look at a different dataset, also from the yelp challenge. This time let's read the business metadata:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"/home/lizhaoyi/datasets/yelp_data/business.json\"\n",
    "f = open(path, 'r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = []\n",
    "for i in range(50000):\n",
    "    dataset.append(json.loads(f.readline()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Again, each entry is a set of key-value, pairs, but note that some of the values are <em>themselves</em> key value pairs:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset[0]['attributes']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Note also that (at least in this dataset) numerical values are already formatted as ints/floats, and don't need to be converted:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset[0]['stars']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Time-and-date-data\">Time and date data<a class=\"anchor-link\" href=\"#Time-and-date-data\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "path = \"/home/lizhaoyi/datasets/yelp_data/review.json\"\n",
    "f = open(path, 'r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = []\n",
    "for i in range(50000):\n",
    "    dataset.append(json.loads(f.readline()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's look at the first review's date:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timeString = dataset[0]['date']\n",
    "print(timeString)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>To handle the string-formatted time data, we can use python's \"time\" library:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timeStruct = time.strptime(timeString, \"%Y-%m-%d\")\n",
    "timeStruct\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The above operation produced a data structure repreresting the time string. Note that we had to specify a format, here a four digit year, two digit month and day, separated by hyphens. Details about formatting strings can be found on <a href=\"https://docs.python.org/2/library/datetime.html\">https://docs.python.org/2/library/datetime.html</a>. E.g. we could also have a string consisting of a time and date:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time.strptime(\"21:36:18, 28/5/2019\", \"%H:%M:%S, %d/%m/%Y\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The above time structure allows us to extract specific information about the date/timestamp, but easier yet might be to convert the timestamps into integers for easier comparison:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timeInt = time.mktime(timeStruct)\n",
    "timeInt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The exact value of this time is the <em>number of seconds since 1970</em>. While not the most obvious format, it does allow for easy comparison between times:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timeInt2 = time.mktime(time.strptime(dataset[99]['date'], \"%Y-%m-%d\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>E.g. the number of seconds between dataset[0] and dataset[99] is...</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timeDiff = timeInt - timeInt2\n",
    "timeDiff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timeDiff / 60 # minutes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timeDiff / (60*60) # hours\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timeDiff / (60*60*24) # days\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The values can also be converted back to a structured time object:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time.gmtime(timeInt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Or we can determine, for example, what the date would be one week later:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time.gmtime(timeInt + 60*60*24*7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Finally It might be useful to augment our dataset to include these numerical time measurements for every sample:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasetWithTimeValues = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for d in dataset:\n",
    "    d['date']\n",
    "    d['timeStruct'] = time.strptime(d['date'], \"%Y-%m-%d\")\n",
    "    d['timeInt'] = time.mktime(d['timeStruct'])\n",
    "    datasetWithTimeValues.append(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The same strategy can also be used to deal with times that have no date attached to them, e.g. let's look at the length of a business's opening hours:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"/home/lizhaoyi/datasets/yelp_data/business.json\"\n",
    "f = open(path, 'r')\n",
    "dataset = []\n",
    "for i in range(50000):\n",
    "    dataset.append(json.loads(f.readline()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset[0]['hours']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's try to calculate how long the business is open on Fridays:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hours = dataset[0]['hours']['Friday']\n",
    "hours\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openTime,closeTime = hours.split('-')\n",
    "openTime,closeTime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timeIntOpen = time.mktime(time.strptime(openTime, \"%H:%M\"))\n",
    "timeIntClose = time.mktime(time.strptime(closeTime, \"%H:%M\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timeIntOpen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timeIntClose\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Note that since we specified no date, these timestamps are assumed to correspond to January 1, 1900:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time.gmtime(timeIntOpen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>However for the purposes of measuring the opening duration, it's sufficient to compute the difference:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(timeIntClose - timeIntOpen) / (60*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Using-pandas-for-Data-Analysis\">Using pandas for Data Analysis<a class=\"anchor-link\" href=\"#Using-pandas-for-Data-Analysis\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Case Study: Amazon Dataset</strong></p>\n",
    "<p>We'll again use the the \"Gift card\" dataset.  Please unzip the file after downloading it and place <strong>amazon_reviews_us_Gift_Card_v1_00.tsv</strong> under the datasets.</p>\n",
    "<p><strong>Objective:</strong> We seek to draw inferences from this dataset, whilst exploring some of the functionalities pandas has to offer.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "giftcard = pd.read_csv('./datasets/amazon_reviews_us_Gift_Card_v1_00.tsv', sep='\\t')\n",
    "print(type(giftcard))\n",
    "giftcard.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "giftcard.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "giftcard['star_rating'].max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "giftcard['star_rating'].min()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "giftcard['star_rating'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "giftcard.isnull().any()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "giftcard.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "giftcard = giftcard.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "giftcard.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = giftcard[['star_rating','helpful_votes','total_votes']]\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.head(100).plot.bar()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.head(100).plot.hist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.head(100).plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_helpful_votes = df[df['helpful_votes'] > 0]\n",
    "print(df.shape)\n",
    "print(df_helpful_votes.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_helpful_votes\n",
    "df_helpful_votes.groupby('total_votes').mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_helpful_votes[['helpful_votes','total_votes']].head(50).plot.bar()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "giftcard.hist(column='star_rating', figsize=(15,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Plotting-with-matplotlib\">Plotting with matplotlib<a class=\"anchor-link\" href=\"#Plotting-with-matplotlib\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's do a simple plot of ratings as a function of the day of the week.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>First we'll import the <em>matplotlib</em> library:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weekRatings = defaultdict(list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for d in datasetWithTimeValues:\n",
    "    day = d['timeStruct'].tm_wday\n",
    "    weekRatings[day].append(d['stars'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weekAverages = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for d in weekRatings:\n",
    "    weekAverages[d] = sum(weekRatings[d]) * 1.0 / len(weekRatings[d])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weekAverages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = list(weekAverages.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y = [weekAverages[x] for x in X]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(X, Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>It might be nicer to plot this as a bar plot:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.bar(X, Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's zoom in to make the differences a bit more visible:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.ylim(3.6, 3.8)\n",
    "plt.bar(X, Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Next let's add some labels:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.ylim(3.6, 3.8)\n",
    "plt.xlabel(\"Weekday\")\n",
    "plt.ylabel(\"Rating\")\n",
    "plt.title(\"Rating as a function of weekday\")\n",
    "plt.bar(X, Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Finally let's rename the ticks to correspond to the days of the week</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.ylim(3.6, 3.8)\n",
    "plt.xlabel(\"Weekday\")\n",
    "plt.ylabel(\"Rating\")\n",
    "plt.xticks([0,1,2,3,4,5,6],['S', 'M', 'T', 'W', 'T', 'F', 'S'])\n",
    "plt.title(\"Rating as a function of weekday\")\n",
    "plt.bar(X, Y)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
