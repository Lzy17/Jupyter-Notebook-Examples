{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Classification\">Classification<a class=\"anchor-link\" href=\"#Classification\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>In this problem we'll set up a simple classifier using sklearn.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>For this exercise, we'll use the polish bankruptcy data, available here:\n",
    "<a href=\"https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data\">https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>First, download the data and save it to your local machine. Then we will read in the file as a csv:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open(\"/home/lizhaoyi/datasets/bankruptcy/5year.arff\", 'r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The data has a slightly odd format (try opening the above file in a text editor to see), so we have to skip the first few lines before we get to the actual csv data.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while not '@data' in f.readline():\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Other than that we read it like a regular csv file, along with some simple data processing as we go</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = []\n",
    "for l in f:\n",
    "    if '?' in l: # Missing entry\n",
    "        continue\n",
    "    l = l.split(',')\n",
    "    values = [1] + [float(x) for x in l]\n",
    "    values[-1] = values[-1] > 0 # Convert to bool\n",
    "    dataset.append(values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Looking at just the last entry (i.e., the label), how many positive values are there?</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sum([x[-1] for x in dataset])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Generate feature and label matrices from the data (in this case, we're just using the features directly from the csv)</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = [values[:-1] for values in dataset]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = [values[-1] for values in dataset]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We'll use the \"linear_model\" library from sklearn, which has a Logistic Regression class</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import linear_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Once the model has finished training, we can use the model to make predictions. Here we just use our training data to make predictions, but we could also use new (i.e., previously unseen) datapoints</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Simple-diagnostics---model-accuracy\">Simple diagnostics - model accuracy<a class=\"anchor-link\" href=\"#Simple-diagnostics---model-accuracy\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The predictions made my the model are just a vector of \"True\" and \"False\" values for each datapoint</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Next we convert this to an array indicating which of the predictions were correct</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correctPredictions = predictions == y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correctPredictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>To compute the accuracy of the model, we are just counting the fraction of \"True\" values in the above vector</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sum(correctPredictions) / len(correctPredictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Classification-with-separate-training/test-splits\">Classification with separate training/test splits<a class=\"anchor-link\" href=\"#Classification-with-separate-training/test-splits\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>In the previous example, we calculated accuracy, but used the same data for evaluation as we used for training. A more robust evaluation would consist of evaluating the model on <em>new</em> data.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Again, we start by reading in the csv data as before.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open(\"/home/lizhaoyi/datasets/bankruptcy/5year.arff\", 'r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while not '@data' in f.readline():\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = []\n",
    "for l in f:\n",
    "    if '?' in l:\n",
    "        continue\n",
    "    l = l.split(',')\n",
    "    values = [1] + [float(x) for x in l]\n",
    "    values[-1] = values[-1] > 0 # Convert to bool\n",
    "    dataset.append(values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We start by splitting the data into training and testing portions. It is important to randomly shuffle the data first, so that these two portions are similar samples of the data.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.shuffle(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = [values[:-1] for values in dataset]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = [values[-1] for values in dataset]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Here we split the data so that the first half (of the shuffled data) is used for training and the rest is used for testing</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = len(X)\n",
    "X_train = X[:N//2]\n",
    "X_test = X[N//2:]\n",
    "y_train = y[:N//2]\n",
    "y_test = y[N//2:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(X), len(X_train), len(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Again we'll use the same Logistic Regression model for training, though this time we'll only train <em>on the training data</em></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import linear_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Below we make predictions in the same way as before, but now do so seperately for the training and test sets.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictionsTrain = model.predict(X_train)\n",
    "predictionsTest = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correctPredictionsTrain = predictionsTrain == y_train\n",
    "correctPredictionsTest = predictionsTest == y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Training accuracy:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sum(correctPredictionsTrain) / len(correctPredictionsTrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Test accuracy:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sum(correctPredictionsTest) / len(correctPredictionsTest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Gradient-descent-(regression)\">Gradient descent (regression)<a class=\"anchor-link\" href=\"#Gradient-descent-(regression)\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Here we'll show how to implement regression using gradient descent. Of course this is not necessary when using a library, though the purpose of this exercise is to demonstrate how gradient-descent-based learning operates in general.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>This exercise is based on the UCI PM2.5 (Air Quality) dataset, available here:\n",
    "<a href=\"https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data\">https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data</a></p>\n",
    "<p>As usual, this data should first be saved to your local disk.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We first read the data as usual, and extract the pm2.5 measurements as outputs to be predicted:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"datasets/PRSA_data_2010.1.1-2014.12.31.csv\"\n",
    "f = open(path, 'r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = []\n",
    "header = f.readline().strip().split(',')\n",
    "for line in f:\n",
    "    line = line.split(',')\n",
    "    dataset.append(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "header.index('pm2.5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = [d for d in dataset if d[5] != 'NA']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>For demonstration we'll build a simple feature vector consisting of only a single feature (temperature), plus an offset. Thus our goal is to predict air quality as a function of temperature.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature(datum):\n",
    "    feat = [1, float(datum[7])] # Temperature\n",
    "    return feat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = [feature(d) for d in dataset]\n",
    "y = [float(d[5]) for d in dataset]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Below we initialize our parameter vector (theta).</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K = len(X[0])\n",
    "K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta = [0.0]*K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>It can help to initialize the model to a solution that's \"close to\" the optimal value. A good initial guess for the offset term is to initialize it to the average value of the label (i.e., the average air quality measurement)</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta[0] = sum(y) / len(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Below are a few utility functions to compute the inner product and norm of a vector. These are also implemented in various libraries (e.g. numpy), and using the library functions would likely result in a more efficient implementation, but the functions are written here just for demonstration purposes.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inner(x,y):\n",
    "    return sum([a*b for (a,b) in zip(x,y)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def norm(x):\n",
    "    return sum([a*a for a in x]) # equivalently, inner(x,x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Derivative-function:\">Derivative function:<a class=\"anchor-link\" href=\"#Derivative-function:\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Most important is our function to compute the derivative. The expression being computed here is the derivative of the objective (the Mean Squared Error) with respect to the parameters (theta), at our current estimate of theta.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def derivative(X, y, theta):\n",
    "    dtheta = [0.0]*len(theta) # Initialize the derivative vector to be a vector of zeros\n",
    "    K = len(theta)\n",
    "    N = len(X)\n",
    "    MSE = 0 # Compute the MSE as we go, just to print it for debugging\n",
    "    for i in range(N):\n",
    "        error = inner(X[i],theta) - y[i]\n",
    "        for k in range(K):\n",
    "            dtheta[k] += 2*X[i][k]*error/N # See the lectures to understand how this expression was derived\n",
    "        MSE += error*error/N\n",
    "    return dtheta, MSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learningRate = 0.003\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Now we iteratively call our derivative function to improve our estimate of theta, by following the direction of the derivative. The details of this function are quite difficult to get right, e.g. if the learning rate or the convergence criteria are not set well the function may not produce a good solution.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while (True):\n",
    "    dtheta,MSE = derivative(X, y, theta)\n",
    "    m = norm(dtheta)\n",
    "    print(\"norm(dtheta) = \" + str(m) + \" MSE = \" + str(MSE))\n",
    "    for k in range(K):\n",
    "        theta[k] -= learningRate * dtheta[k]\n",
    "    if m < 0.01: break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Once gradient descent has converged, we can examine the learned value of theta:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Gradient-descent-in-Tensorflow\">Gradient descent in Tensorflow<a class=\"anchor-link\" href=\"#Gradient-descent-in-Tensorflow\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Although the above gradient descent code produced an acceptable solution, it was (a) difficult to implement; (b) difficult to tune the optimization process (e.g. learning rates and stopping criteria); and (c) inefficient (i.e., slow). Using libraries like tensorflow can help to alleviate these issues.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>First you will need to set up a working install of tensorflow. See installation instructions here:\n",
    "<a href=\"https://www.tensorflow.org/install\">https://www.tensorflow.org/install</a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Otherwise we read in the data as before</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"datasets/PRSA_data_2010.1.1-2014.12.31.csv\"\n",
    "f = open(path, 'r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = []\n",
    "header = f.readline().strip().split(',')\n",
    "for line in f:\n",
    "    line = line.split(',')\n",
    "    dataset.append(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "header.index('pm2.5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = [d for d in dataset if d[5] != 'NA']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature(datum):\n",
    "    feat = [1, float(datum[7]), float(datum[8]), float(datum[10])] # Temperature, pressure, and wind speed\n",
    "    return feat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = [feature(d) for d in dataset]\n",
    "y = [float(d[5]) for d in dataset]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = tf.constant(y, shape=[len(y),1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K = len(X[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The main advantage of tensorflow is that we don't have to compute the gradient - tensorflow will compute it for us. Instead, we have to implement our <em>objective</em> (i.e., the MSE) in terms of tensorflow operations:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MSE(X, y, theta):\n",
    "  return tf.reduce_mean((tf.matmul(X,theta) - y)**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Next we tell tensorflow that theta is our vector of variables to be optimized (we also specify its shape and initial values)</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta = tf.Variable(tf.constant([0.0]*K, shape=[K,1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Here we select an optimizer, which is essentially a specific gradient descent implementation. The parameter passed to the optimizer is a learning rate.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Then we tell tensorflow that our MSE function is the objective to be optimized.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "objective = MSE(X,y,theta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Then we tell tensorflow that this objective should be minimized (i.e., we are trying to minimize an error, rather than maximizing an accuracy), and initialize the session.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = optimizer.minimize(objective)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Finally we run 1000 iterations of gradient descent. Note how fast this is compared to our own implementation!</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for iteration in range(1000):\n",
    "  cvalues = sess.run([train, objective])\n",
    "  print(\"objective = \" + str(cvalues[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Once gradient descent has converged, we can print out the results (i.e., theta)</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with sess.as_default():\n",
    "  print(MSE(X, y, theta).eval())\n",
    "  print(theta.eval())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
